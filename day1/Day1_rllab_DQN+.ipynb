{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day1_rllab_DQN+.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "wP3KREMIG196",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RLLAB setup scripts for google colab\n",
        "Install packages with compatible versions"
      ]
    },
    {
      "metadata": {
        "id": "2J5ROkw6Gcxq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!apt-get -qq -y install xvfb freeglut3-dev ffmpeg > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvacEH-tGtI1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q path.py\n",
        "!pip install -q pyprind\n",
        "!pip install -q cached_property\n",
        "!pip install -q gym==0.7.4\n",
        "!pip install -q theano==0.8.2\n",
        "!pip install -q git+https://github.com/neocxi/Lasagne.git@484866cf8b38d878e92d521be445968531646bb8#egg=Lasagne\n",
        "  \n",
        "!pip install -q PyOpenGL piglet pyglet pyvirtualdisplay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TWKA_0xQHGAS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install box2d-py mako==1.0.7 Pygame JSAnimation imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iDxIzxg9HJhp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kekim/rllab.git rllab-git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hq4UosxRHMkq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -a ./rllab-git/* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUHGgASMNg2N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DQN Plus on Acrobot (OpenAI Gym version)\n",
        "**Important!**\n",
        "Before running the following cell, make sure rllab is set up properly in your current runtime by executing codes in RLLAB setup scripts."
      ]
    },
    {
      "metadata": {
        "id": "XA0g5MBZHQ3o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Implement DQN Plus (DDQN w/ Prioritized Experience Replay) Algorithm**"
      ]
    },
    {
      "metadata": {
        "id": "EJcqSePquDny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Import necessary packages\n",
        "(Execute **once again** if you encounter an error)"
      ]
    },
    {
      "metadata": {
        "id": "C49pvNj5HooC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## DQN_Plus_GYM_CARTPOLE_With_RUN_EXP_LITE ##########\n",
        "from rllab.envs.gym_env import GymEnv\n",
        "from dqn.policies.categorical_mlp_q_policy import CategoricalMlpQPolicy\n",
        "from dqn.exploration_strategies.eps_greedy_strategy import EpsilonGreedyStrategy\n",
        "\n",
        "# from dqn.algos.dqn import DQN\n",
        "\n",
        "from rllab.envs.normalized_env import normalize\n",
        "from rllab.misc.instrument import run_experiment_lite\n",
        "from rllab.q_functions.continuous_mlp_q_function import ContinuousMLPQFunction\n",
        "\n",
        "import lasagne.nonlinearities as NL\n",
        "'''\n",
        "import gym.envs\n",
        "from rllab.envs.gym_env import GymEnv\n",
        "from envs.proxy_gym_env import ProxyGymEnv\n",
        "from misc.retro_wrappers import wrap_deepmind_retro\n",
        "from policies.categorical_mlp_q_policy import CategoricalMlpQPolicy\n",
        "from exploration_strategies.eps_greedy_strategy import EpsilonGreedyStrategy\n",
        "\n",
        "from algos.dqn import DQN\n",
        "\n",
        "from rllab.envs.normalized_env import normalize\n",
        "from rllab.misc.instrument import run_experiment_lite\n",
        "from rllab.q_functions.continuous_mlp_q_function import ContinuousMLPQFunction\n",
        "\n",
        "import lasagne.nonlinearities as NL\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAnQANVpuL2c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Implement DQN Plus algorithm"
      ]
    },
    {
      "metadata": {
        "id": "ZT3OayOoO6F9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from rllab.algos.base import RLAlgorithm\n",
        "from rllab.misc.overrides import overrides\n",
        "from rllab.misc import special\n",
        "from rllab.misc import ext\n",
        "from rllab.sampler import parallel_sampler\n",
        "from rllab.plotter import plotter\n",
        "from functools import partial\n",
        "import rllab.misc.logger as logger\n",
        "import theano.tensor as TT\n",
        "import pickle as pickle\n",
        "import numpy as np\n",
        "import pyprind\n",
        "import lasagne\n",
        "from collections import deque\n",
        "from rllab.algos.ddpg import parse_update_method#, SimpleReplayPool\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "def huber_loss(diffs, clip):\n",
        "    return TT.mean(TT.switch(abs(diffs) < clip, 0.5 * TT.square(diffs), clip * (abs(diffs) - 0.5 * clip)))\n",
        "    \n",
        "\n",
        "class PriorityReplayPool(object):\n",
        "    def __init__(\n",
        "            self, max_pool_size, observation_dim, action_dim, alpha, beta, n_steps):\n",
        "        self._observation_dim = observation_dim\n",
        "        self._action_dim = action_dim\n",
        "        self._max_pool_size = max_pool_size\n",
        "        self._observations = np.zeros(\n",
        "            (max_pool_size, observation_dim),\n",
        "        )\n",
        "        self._actions = np.zeros(\n",
        "            (max_pool_size, action_dim),\n",
        "        )\n",
        "        self._rewards = np.zeros(max_pool_size)\n",
        "        self._terminals = np.zeros(max_pool_size, dtype='uint8')\n",
        "\n",
        "        self._td_errs = np.zeros(max_pool_size)\n",
        "        self._ranks = np.zeros(max_pool_size)\n",
        "        self._probs = np.zeros(max_pool_size)\n",
        "        self._weights = np.zeros(max_pool_size)#np.zeros(max_pool_size)\n",
        "        \n",
        "        # A scheduler is requried to make Alpha & Beta reach 1 at the end of training\n",
        "        self._alpha = alpha\n",
        "        self._beta = beta\n",
        "        self._beta_increment = 2*(1.0-beta)/n_steps\n",
        "        # self._beta_increment = 0.002#0.0000075#0.0000015#\n",
        "\n",
        "        self._bottom = 0\n",
        "        self._top = 0\n",
        "        self._size = 0\n",
        "        self._actual_size=0\n",
        "        self._max_pool_size = max_pool_size\n",
        "\n",
        "    def add_sample(self, observation, action, reward, terminal):\n",
        "        if self._actual_size < self._max_pool_size:\n",
        "            self._actual_size += 1\n",
        "\n",
        "        self._observations[self._top] = observation\n",
        "        self._actions[self._top] = action\n",
        "        self._rewards[self._top] = reward\n",
        "        self._terminals[self._top] = terminal\n",
        "\n",
        "        self._td_errs[self._top] = np.max([np.max(self._td_errs), 0.000001])\n",
        "        # self._td_errs[self._top] = np.max(self._td_errs)\n",
        "        # self._weights[self._top] = np.max(self._weights)\n",
        "\n",
        "        self._top = (self._top + 1) % self._max_pool_size\n",
        "        if self._size >= self._max_pool_size:\n",
        "            self._bottom = (self._bottom + 1) % self._max_pool_size\n",
        "        else:\n",
        "            self._size += 1\n",
        "\n",
        "    def update_samples(self, td_errs, indices):\n",
        "        # Sample update should be done in batch\n",
        "        self._td_errs[indices] = td_errs+0.000001\n",
        "        # print('td_erros:', self._td_errs.shape)\n",
        "\n",
        "    def update_all(self):\n",
        "\n",
        "        self._probs = np.power(self._td_errs, self._alpha)\n",
        "        self._probs = self._probs / np.sum(self._probs)\n",
        "        # print(self._probs)\n",
        "        self._weights = np.power(self._actual_size*self._probs, (-1.0)*self._beta)\n",
        "        self._weights = self._weights / np.max(self._weights)\n",
        "        '''\n",
        "        self._ranks[:self._actual_size] = rankdata(self._td_errs[:self._actual_size], method='min')\n",
        "        self._probs[:self._actual_size] = np.power(1.0/self._ranks[:self._actual_size], self._alpha)\n",
        "        self._probs = self._probs / np.sum(self._probs)\n",
        "        self._weights = np.power(self._actual_size*self._probs, (-1.0)*self._beta)\n",
        "        self._weights = self._weights / np.max(self._weights)\n",
        "        '''\n",
        "\n",
        "    def priority_batch(self, batch_size):\n",
        "        assert self._size > batch_size\n",
        "\n",
        "        self.update_all()\n",
        "\n",
        "        indices = np.random.choice(self._max_pool_size,\n",
        "                                    batch_size+1,\n",
        "                                    replace=False,\n",
        "                                    p=self._probs)\n",
        "        # print(self._probs[self._actual_size])\n",
        "        if self._size > self._max_pool_size:\n",
        "            indices = indices[:batch_size]\n",
        "        else:\n",
        "            temp = np.where(indices == self._size-1)[0]\n",
        "            if temp.shape[0] == 0:\n",
        "                indices = indices[:batch_size]\n",
        "            else:\n",
        "                indices = np.delete(indices, temp[0])\n",
        "\n",
        "        assert indices.shape[0] == batch_size\n",
        "\n",
        "        transition_indices = (indices+1) % self._max_pool_size\n",
        "\n",
        "        # Annealing bias by incrementing beta... Careful consideration is requried.\n",
        "        self._beta = np.min([1.0, self._beta + self._beta_increment])\n",
        "\n",
        "        return dict(\n",
        "            observations=self._observations[indices],\n",
        "            actions=self._actions[indices],\n",
        "            rewards=self._rewards[indices],\n",
        "            terminals=self._terminals[indices],\n",
        "            indices=indices,\n",
        "            weights=self._weights[indices],\n",
        "            next_observations=self._observations[transition_indices]\n",
        "        )\n",
        "\n",
        "\n",
        "    @property\n",
        "    def size(self):\n",
        "        return self._size\n",
        "\n",
        "\n",
        "class DQN_PLUS(RLAlgorithm):\n",
        "    \"\"\"\n",
        "    Deep Q Network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            env,\n",
        "            policy,\n",
        "            es,\n",
        "            batch_size=32,\n",
        "            alpha=0.6,\n",
        "            beta=0.4,\n",
        "            n_steps=8000000,\n",
        "            min_pool_size=1000000,\n",
        "            replay_pool_size=1000000,\n",
        "            discount=0.99,\n",
        "            policy_update_method='adam',\n",
        "            policy_learning_rate=1e-3,\n",
        "            target_model_update=10000,\n",
        "            n_updates_per_sample=1,\n",
        "            train_epoch_interval=10000,\n",
        "            max_path_length=np.inf,\n",
        "            n_eval_samples=5,\n",
        "            delta_clip=np.inf,\n",
        "            include_horizon_terminal_transitions=False,\n",
        "            plot=False,\n",
        "            pause_for_plot=False):\n",
        "        \"\"\"\n",
        "        :param env: Environment\n",
        "        :param policy: Policy\n",
        "        :param qf: Q function\n",
        "        :param es: Exploration strategy\n",
        "        :param batch_size: Number of samples for each minibatch.\n",
        "        :param n_epochs: Number of epochs. Policy will be evaluated after each epoch.\n",
        "        :param epoch_length: How many timesteps for each epoch.\n",
        "        :param min_pool_size: Minimum size of the pool to start training.\n",
        "        :param replay_pool_size: Size of the experience replay pool.\n",
        "        :param discount: Discount factor for the cumulative return.\n",
        "        :param max_path_length: Discount factor for the cumulative return.\n",
        "        :param qf_weight_decay: Weight decay factor for parameters of the Q function.\n",
        "        :param qf_update_method: Online optimization method for training Q function.\n",
        "        :param qf_learning_rate: Learning rate for training Q function.\n",
        "        :param policy_weight_decay: Weight decay factor for parameters of the policy.\n",
        "        :param policy_update_method: Online optimization method for training the policy.\n",
        "        :param policy_learning_rate: Learning rate for training the policy.\n",
        "        :param n_eval_samples: Number of samples (timesteps) for evaluating the policy.\n",
        "        :param soft_target_tau: Interpolation parameter for doing the soft target update.\n",
        "        :param n_updates_per_sample: Number of Q function and policy updates per new sample obtained\n",
        "        :param scale_reward: The scaling factor applied to the rewards when training\n",
        "        :param include_horizon_terminal_transitions: whether to include transitions with terminal=True because the\n",
        "        horizon was reached. This might make the Q value back up less stable for certain tasks.\n",
        "        :param plot: Whether to visualize the policy performance after each train_epoch_interval.\n",
        "        :param pause_for_plot: Whether to pause before continuing when plotting.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.policy = policy\n",
        "        self.es = es\n",
        "        self.batch_size = batch_size\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "        self.min_pool_size = min_pool_size\n",
        "        self.replay_pool_size = replay_pool_size\n",
        "        self.discount = discount\n",
        "        self.n_steps = n_steps\n",
        "        \n",
        "        self.policy_learning_rate = policy_learning_rate\n",
        "        self.policy_update_method = parse_update_method(\n",
        "                policy_update_method,\n",
        "                learning_rate=policy_learning_rate,\n",
        "        )\n",
        "        \n",
        "        assert target_model_update >= 0\n",
        "        if target_model_update >= 1:\n",
        "            self.target_model_update = int(target_model_update) # hard update every xx steps\n",
        "        else:\n",
        "            self.target_model_update = float(target_model_update) # soft update\n",
        "            \n",
        "        self.n_updates_per_sample = n_updates_per_sample\n",
        "        self.train_epoch_interval = train_epoch_interval\n",
        "        self.max_path_length = max_path_length\n",
        "        self.n_eval_samples = n_eval_samples\n",
        "        self.delta_clip = delta_clip\n",
        "        \n",
        "        self.include_horizon_terminal_transitions = include_horizon_terminal_transitions\n",
        "        self.plot = plot\n",
        "        self.pause_for_plot = pause_for_plot\n",
        "\n",
        "        self.qf_loss_averages = []\n",
        "        self.q_averages = []\n",
        "        self.y_averages = []\n",
        "        self.paths = []\n",
        "        self.es_path_returns = []\n",
        "        self.paths_samples_cnt = 0\n",
        "\n",
        "        self.opt_info = None\n",
        "\n",
        "    def start_worker(self):\n",
        "        parallel_sampler.populate_task(self.env, self.policy)\n",
        "        if self.plot:\n",
        "            plotter.init_plot(self.env, self.policy)\n",
        "\n",
        "    @overrides\n",
        "    def train(self):\n",
        "        # This seems like a rather sequential method\n",
        "        pool = PriorityReplayPool(\n",
        "        # pool = SimpleReplayPool(\n",
        "            max_pool_size=int(self.replay_pool_size),\n",
        "            observation_dim=self.env.observation_space.flat_dim,\n",
        "            action_dim=self.env.action_space.flat_dim,\n",
        "            alpha=self.alpha,\n",
        "            beta=self.beta,\n",
        "            n_steps=self.n_steps\n",
        "        )\n",
        "            \n",
        "        self.start_worker()\n",
        "\n",
        "        self.init_opt()\n",
        "        itr = 0\n",
        "        path_length = 0\n",
        "        path_return = 0\n",
        "        terminal = False\n",
        "        \n",
        "        observation = self.env.reset()\n",
        "\n",
        "        sample_policy = pickle.loads(pickle.dumps(self.policy))\n",
        "\n",
        "        train_epoch = 0\n",
        "        \n",
        "        while train_epoch * self.train_epoch_interval < self.n_steps: \n",
        "            logger.push_prefix('step #%d | ' % (train_epoch * self.train_epoch_interval))\n",
        "            logger.log(\"Training started\")\n",
        "            for train_epoch_step in pyprind.prog_bar(range(self.train_epoch_interval)):\n",
        "                # Execute policy\n",
        "                if terminal or path_length > self.max_path_length:\n",
        "                    # Note that if the last step step ends an episode, the very\n",
        "                    # last state and observation will be ignored and not added\n",
        "                    # to the replay pool\n",
        "                    # print('terminal! ' + str(itr))\n",
        "                    observation = self.env.reset()\n",
        "                    self.es.reset()\n",
        "                    sample_policy.reset()\n",
        "                    self.es_path_returns.append(path_return)\n",
        "                    path_length = 0\n",
        "                    path_return = 0\n",
        "                action = self.es.get_action(itr, observation, policy=sample_policy)  # qf=qf)\n",
        "\n",
        "                next_observation, reward, terminal, _ = self.env.step(action)\n",
        "                path_length += 1\n",
        "                path_return += reward\n",
        "\n",
        "                \n",
        "                pool.add_sample(self.env.observation_space.flatten(observation), \n",
        "                                self.env.action_space.flatten(action), \n",
        "                                reward, \n",
        "                                terminal) ## clipping?\n",
        "\n",
        "                observation = next_observation\n",
        "\n",
        "                if pool.size >= self.min_pool_size:\n",
        "                    for update_itr in range(self.n_updates_per_sample):\n",
        "                        # Train policy\n",
        "                        # batch = pool.random_batch(self.batch_size)\n",
        "                        batch = pool.priority_batch(self.batch_size)\n",
        "                        td_errs, indices = self.do_training(itr, batch)\n",
        "                        # print(td_errs)\n",
        "                        pool.update_samples(td_errs, indices)\n",
        "                    sample_policy.set_param_values(self.policy.get_param_values())\n",
        "                \n",
        "                itr += 1\n",
        "\n",
        "            logger.log(\"Training finished\")\n",
        "            if pool.size >= self.min_pool_size:\n",
        "                self.evaluate(train_epoch * self.train_epoch_interval, pool)\n",
        "                if self.n_eval_samples > 0: # we performed rollout!\n",
        "                    observation = self.env.reset()\n",
        "                params = self.get_epoch_snapshot(train_epoch * self.train_epoch_interval)\n",
        "                logger.save_itr_params(train_epoch * self.train_epoch_interval, params)\n",
        "            logger.dump_tabular(with_prefix=False)\n",
        "            logger.pop_prefix()\n",
        "            train_epoch += 1\n",
        "            if self.plot:\n",
        "                self.update_plot()\n",
        "                if self.pause_for_plot:\n",
        "                    input(\"Plotting evaluation run: Press Enter to \"\n",
        "                              \"continue...\")\n",
        "        self.env.terminate()\n",
        "        self.policy.terminate()\n",
        "\n",
        "    def init_opt(self):\n",
        "        # First, create \"target\" policy and Q functions\n",
        "        target_policy = pickle.loads(pickle.dumps(self.policy))\n",
        "\n",
        "        # y need to be computed first\n",
        "        obs = self.env.observation_space.new_tensor_variable(\n",
        "            'obs',\n",
        "            extra_dims=1,\n",
        "        )\n",
        "\n",
        "        # The yi values are computed separately as above and then passed to\n",
        "        # the training functions below\n",
        "        action = self.env.action_space.new_tensor_variable(\n",
        "            'action',\n",
        "            extra_dims=1,\n",
        "        )\n",
        "\n",
        "        weights = TT.vector('weights')\n",
        "        yvar = TT.vector('ys')\n",
        "\n",
        "        qval = self.policy.get_qval_sym(obs, action).flatten()\n",
        "\n",
        "        qf_loss = TT.mean(weights*TT.square(yvar - qval))\n",
        "        qf_reg_loss = qf_loss # + qf_weight_decay_term\n",
        "       \n",
        "        qf_updates = self.policy_update_method(\n",
        "            qf_reg_loss, \n",
        "            self.policy.get_params(trainable=True))\n",
        "\n",
        "        f_train_qf = ext.compile_function(\n",
        "            inputs=[yvar, obs, action, weights],\n",
        "            outputs=[qf_loss, qval],\n",
        "            updates=qf_updates\n",
        "        )\n",
        "        \n",
        "        # qval_test = self.policy.get_qval_sym_test(obs, action)\n",
        "        \n",
        "#         f_train_qf_test = ext.compile_function(\n",
        "#             inputs=[yvar, obs, action],\n",
        "#             outputs=qval_test\n",
        "#         )\n",
        "\n",
        "        self.opt_info = dict(\n",
        "            f_train_qf=f_train_qf,\n",
        "            # f_train_qf_test=f_train_qf_test,\n",
        "            target_policy=target_policy,\n",
        "        )\n",
        "\n",
        "    def do_training(self, itr, batch):\n",
        "        \n",
        "        # obs, actions, next_obs should be all flattened\n",
        "        obs, actions, rewards, next_obs, indices, weights, terminals = ext.extract(\n",
        "            batch,\n",
        "            \"observations\", \"actions\", \"rewards\", \"next_observations\",\n",
        "            \"indices\", \"weights\",\n",
        "            \"terminals\"\n",
        "        )\n",
        "        \n",
        "        target_policy = self.opt_info[\"target_policy\"]\n",
        "        _, target_actions_info = target_policy.get_actions(next_obs)\n",
        "        next_actions, cur_actions_info = self.policy.get_actions(next_obs)\n",
        "        next_qvals = target_actions_info['q'][range(self.batch_size),next_actions]\n",
        "\n",
        "        cur_qvals = cur_actions_info['q'][range(self.batch_size),next_actions]\n",
        "        \n",
        "        if np.any(np.isnan(next_qvals)):\n",
        "            print(itr)\n",
        "            print(target_policy.get_param_values())\n",
        "            print(next_qvals)\n",
        "            assert False\n",
        "        \n",
        "        ys = rewards + (1. - terminals) * self.discount * next_qvals\n",
        "\n",
        "        td_errs = np.abs(ys - cur_qvals)\n",
        "        \n",
        "        f_train_qf = self.opt_info[\"f_train_qf\"]  \n",
        "        qf_loss, qval = f_train_qf(ys, obs, actions, weights)\n",
        "\n",
        "        assert ys.shape == qval.shape\n",
        "\n",
        "\n",
        "        if self.target_model_update >= 1 and itr % self.target_model_update == 0:\n",
        "            target_policy.set_param_values(self.policy.get_param_values())\n",
        "        elif self.target_model_update < 1:\n",
        "            target_policy.set_param_values(\n",
        "                target_policy.get_param_values() * (1.0 - self.target_model_update) + \n",
        "                self.policy.get_param_values() * self.target_model_update) \n",
        "\n",
        "        self.qf_loss_averages.append(qf_loss)\n",
        "        self.q_averages.append(qval)\n",
        "        self.y_averages.append(ys)\n",
        "\n",
        "        return td_errs, indices \n",
        "\n",
        "    def evaluate(self, epoch, pool):\n",
        "        \n",
        "        logger.record_tabular('Epoch', epoch)\n",
        "        \n",
        "        if self.n_eval_samples > 0:\n",
        "            logger.log(\"Collecting samples for evaluation\")\n",
        "            paths = parallel_sampler.sample_paths(\n",
        "                policy_params=self.policy.get_param_values(),\n",
        "                max_samples=self.n_eval_samples,\n",
        "                max_path_length=self.max_path_length,\n",
        "            )\n",
        "\n",
        "            average_discounted_return = np.mean(\n",
        "                [special.discount_return(path[\"rewards\"], self.discount) for path in paths]\n",
        "            )\n",
        "\n",
        "            returns = [sum(path[\"rewards\"]) for path in paths]\n",
        "            \n",
        "            average_action = np.mean(np.square(np.concatenate(\n",
        "                                    [path[\"actions\"] for path in paths])))\n",
        "            \n",
        "            logger.record_tabular('AverageReturn', np.mean(returns))\n",
        "            logger.record_tabular('StdReturn', np.std(returns))\n",
        "            logger.record_tabular('MaxReturn', np.max(returns))\n",
        "            logger.record_tabular('MinReturn', np.min(returns))\n",
        "            \n",
        "            logger.record_tabular('AverageDiscountedReturn', average_discounted_return)\n",
        "            \n",
        "            logger.record_tabular('AverageAction', average_action)\n",
        "            \n",
        "            self.env.log_diagnostics(paths)\n",
        "            self.policy.log_diagnostics(paths)\n",
        "\n",
        "        all_qs = np.concatenate(self.q_averages)\n",
        "        all_ys = np.concatenate(self.y_averages)\n",
        "\n",
        "        average_q_loss = np.mean(self.qf_loss_averages)\n",
        "        \n",
        "\n",
        "        policy_reg_param_norm = np.linalg.norm(\n",
        "            self.policy.get_param_values(regularizable=True)\n",
        "        )\n",
        "#         qfun_reg_param_norm = np.linalg.norm(\n",
        "#             self.qf.get_param_values(regularizable=True)\n",
        "#         )\n",
        "          \n",
        "        if len(self.es_path_returns) > 0:\n",
        "            logger.record_tabular('AverageEsReturn',\n",
        "                                  np.mean(self.es_path_returns))\n",
        "            logger.record_tabular('StdEsReturn',\n",
        "                                  np.std(self.es_path_returns))\n",
        "            logger.record_tabular('MaxEsReturn',\n",
        "                                  np.max(self.es_path_returns))\n",
        "            logger.record_tabular('MinEsReturn',\n",
        "                                  np.min(self.es_path_returns))\n",
        "            logger.record_tabular('NbEs', len(self.es_path_returns))\n",
        "        \n",
        "        logger.record_tabular('AverageQLoss', average_q_loss)\n",
        "        logger.record_tabular('AverageQ', np.mean(all_qs))\n",
        "        logger.record_tabular('AverageAbsQ', np.mean(np.abs(all_qs)))\n",
        "        logger.record_tabular('AverageY', np.mean(all_ys))\n",
        "        logger.record_tabular('AverageAbsY', np.mean(np.abs(all_ys)))\n",
        "        logger.record_tabular('AverageAbsQYDiff',\n",
        "                              np.mean(np.abs(all_qs - all_ys)))\n",
        "\n",
        "        logger.record_tabular('PolicyRegParamNorm',\n",
        "                              policy_reg_param_norm)\n",
        "\n",
        "        self.qf_loss_averages = []\n",
        "\n",
        "        self.q_averages = []\n",
        "        self.y_averages = []\n",
        "        self.es_path_returns = []\n",
        "\n",
        "    def update_plot(self):\n",
        "        if self.plot:\n",
        "            plotter.update_plot(self.policy, self.max_path_length)\n",
        "\n",
        "    def get_epoch_snapshot(self, epoch):\n",
        "        return dict(\n",
        "            env=self.env,\n",
        "            epoch=epoch,\n",
        "            policy=self.policy,\n",
        "            target_policy=self.opt_info[\"target_policy\"],\n",
        "            es=self.es,\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xF6kAwo57hb6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Execute Your Algorithm**"
      ]
    },
    {
      "metadata": {
        "id": "UjHQm_6t7wK1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Activate a virtual display"
      ]
    },
    {
      "metadata": {
        "id": "oIUuJMGv7u8O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "import os\n",
        "os.environ[\"DISPLAY\"] = \":\" + str(display.display) + \".\" + str(display.screen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x6yM_2LavPBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Create & Run a RL task for Cartpole"
      ]
    },
    {
      "metadata": {
        "id": "74oGATzdIO9b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Creating & Running a task #####\n",
        "def run_task(*_):\n",
        "    # env = GymEnv('Acrobot-v1', record_video=True, record_log=True)\n",
        "    env = GymEnv('Acrobot-v1', record_video=False, record_log=False)\n",
        "    \n",
        "    policy = CategoricalMlpQPolicy(\n",
        "        name='dqn_policy',\n",
        "        env_spec=env.spec,\n",
        "        # The neural network policy should have two hidden layers, each with 32 hidden units.\n",
        "        hidden_sizes=[64],\n",
        "        hidden_nonlinearity=NL.rectify\n",
        "    )\n",
        "    \n",
        "    n_steps = 80000\n",
        "    es = EpsilonGreedyStrategy(env_spec=env.spec, max_eps=0.5, min_eps=0.05, decay_period=n_steps//4)\n",
        "    \n",
        "    algo = DQN_PLUS(\n",
        "        env=env,\n",
        "        policy=policy,\n",
        "        es=es,\n",
        "        batch_size=20,\n",
        "        alpha=0.6,\n",
        "        beta=0.4,\n",
        "        n_steps=n_steps,\n",
        "        min_pool_size=100,\n",
        "        replay_pool_size=200,\n",
        "        train_epoch_interval=1000,\n",
        "        max_path_length=500,\n",
        "        policy_update_method='sgd',\n",
        "        policy_learning_rate=0.005,\n",
        "        target_model_update=0.5,\n",
        "        n_eval_samples=0,\n",
        "        # Uncomment both lines (this and the plot parameter below) to enable plotting\n",
        "        # plot=True,\n",
        "    )\n",
        "    algo.train()\n",
        "\n",
        "mypath = './acrobot_dqn_plus/'\n",
        "\n",
        "run_experiment_lite(\n",
        "    run_task,\n",
        "    log_dir=mypath,\n",
        "    # Number of parallel workers for sampling\n",
        "    n_parallel=1,\n",
        "    # Only keep the snapshot parameters for the last iteration\n",
        "    snapshot_mode=\"last\",\n",
        "    # Specifies the seed for the experiment. If this is not provided, a random seed\n",
        "    # will be used\n",
        "    seed=1,\n",
        "    # plot=True,\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdDOU5hwKlW4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Average Reward Plotting**"
      ]
    },
    {
      "metadata": {
        "id": "ip1bXHMtvtWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- You can evaluate how your agent is being trained with reward it gets in every iteration. \n",
        "- Whenever you execute the code 'run_experiment_lite', it will generate a experiment directory.\n",
        "- (/content/acrobot_dqn_plus/)\n",
        "- Please update the value of '**mypath**' and specify your new experiment directory name. "
      ]
    },
    {
      "metadata": {
        "id": "RlIgTMPOKqHX",
        "colab_type": "code",
        "outputId": "6b2548e3-fac5-4406-8142-1809e5928854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import joblib\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "# mypath = './acrobot_dqn_plus/'\n",
        "\n",
        "plots = []\n",
        "legends = []\n",
        "returns = []\n",
        "with open(osp.join(mypath, 'progress.csv'), 'rt') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        if row['AverageEsReturn']:\n",
        "            returns.append(float(row['AverageEsReturn']))\n",
        "returns = np.array(returns)\n",
        "plots.append(plt.plot(returns)[0])\n",
        "legends.append('AverageEsReturn')\n",
        "plt.legend(plots, legends)\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2e7b3adf28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rWDQUoPePLDx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4. Play Videos of your Agent Behavior**"
      ]
    },
    {
      "metadata": {
        "id": "AhdxUQuozcRv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- You can watch how your agent's behavior improves.\n",
        "- If you haven't update 'mypath' in the code above, you need to update it here.\n",
        "- (/content/acrobot_dqn_plus/)"
      ]
    },
    {
      "metadata": {
        "id": "TPjtJ3IjPY5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython import display as pythondisplay\n",
        "# from pyvirtualdisplay import Display\n",
        "\n",
        "# from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from JSAnimation import IPython_display\n",
        "from IPython.display import HTML\n",
        "\n",
        "import imageio\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "def plot_movie_js(image_array, filename):\n",
        "    dpi = 10.0\n",
        "    xpixels, ypixels = image_array[0].shape[0], image_array[0].shape[1]\n",
        "    fig = plt.figure(figsize=(ypixels/(dpi), xpixels/(dpi)), dpi=dpi)\n",
        "    fig.suptitle(filename, fontsize=160)\n",
        "    # fig.set_xlabel(filename, fontsize=160)\n",
        "    # fig.xlabel(filename, fontsize=160)\n",
        "    im = plt.figimage(image_array[0])\n",
        "\n",
        "    def animate(i):\n",
        "        im.set_array(image_array[i])\n",
        "        return (im,)\n",
        "    \n",
        "    anim = animation.FuncAnimation(fig, animate, frames=len(image_array))\n",
        "    pythondisplay.display(IPython_display.display_animation(anim))\n",
        "\n",
        "# mypath = './acrobot_dqn_plus/'\n",
        "mypath += 'gym_log/'\n",
        "mp4files = [f for f in listdir(mypath) if f.endswith(\".mp4\")]\n",
        "mp4files.sort()\n",
        "\n",
        "\n",
        "for filename in mp4files:\n",
        "    vid = imageio.get_reader(join(mypath, filename),  'ffmpeg')\n",
        "    # print(len(vid))\n",
        "    # print(vid.get_data(0).shape)\n",
        "\n",
        "    screenlist = []\n",
        "    for i in range(len(vid)):\n",
        "        image = vid.get_data(i)\n",
        "        screenlist.append(image)\n",
        "        # fig = plt.figure()\n",
        "        # fig.suptitle('image #{}'.format(i), fontsize=20)\n",
        "        # plt.imshow(image)\n",
        "\n",
        "    plot_movie_js(screenlist, filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}